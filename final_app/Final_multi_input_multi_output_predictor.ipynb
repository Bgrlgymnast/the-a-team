{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multioutput import MultiOutputRegressor, MultiOutputClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import classification_report, mean_squared_error, accuracy_score  # Include accuracy_score for evaluation\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sqlalchemy import create_engine, inspect\n",
    "import psycopg2 \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "pres_gdp = pd.read_csv(\".resources/president_gdp-94.csv\")\n",
    "pres_terms = pd.read_csv(\".resources/president_terms-94.csv\",encoding=\"UTF-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "pres_gdp.columns = pres_gdp.columns.str.lower()\n",
    "pres_gdp.columns = pres_gdp.columns.str.replace(\" \",\"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "pres_terms.columns = pres_terms.columns.str.lower()\n",
    "pres_terms.columns = pres_terms.columns.str.replace(\" \",\"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PostgreSQL connection parameters\n",
    "postgres_params = {\n",
    "    \"database\": \"postgres\", # Insert the name of database\n",
    "    \"user\": \"postgres\",     # Insert username if different\n",
    "    \"password\": KEY        # Insert your password\n",
    "    \"host\": \"localhost\",    # Replace with your PostgreSQL host if not local\n",
    "    \"port\": 5432,\n",
    "    \"options\": \"-c search_path=dbo,public\"}\n",
    "\n",
    "# Establish a connection to PostgreSQL\n",
    "conn_str = \"postgresql+psycopg2://{user}:{password}@{host}:{port}/{database}\".format(**postgres_params)\n",
    "postgres_engine = create_engine(conn_str)\n",
    "\n",
    "# Write DataFrame to PostgreSQL\n",
    "pres_gdp.to_sql('pres_gdp', con=postgres_engine, index=False, if_exists='replace')\n",
    "pres_terms.to_sql('pres_terms', con=postgres_engine, index=False, if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "query=\"\"\"\n",
    "select * from pres_terms;\n",
    "\"\"\"\n",
    "pres_terms = pd.read_sql(sql= query, con= postgres_engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "query1=\"\"\"\n",
    "select * from pres_gdp;\n",
    "\"\"\"\n",
    "pres_gdp= pd.read_sql(sql= query1, con= postgres_engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_c = ['Year', 'Name', 'VP', 'BDay', 'Party', 'sign', 'BMonth', 'GDP Growth', 'Population Growth']\n",
    "cat_c = [x.lower() for x in cat_c]\n",
    "cat_c = [x.replace(\" \",\"_\") for x in cat_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_c = ['Year', 'GDP Percent Growth', 'Population Percent Growth']\n",
    "num_c = [x.lower() for x in num_c]\n",
    "num_c = [x.replace(\" \",\"_\") for x in num_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model for sign...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.33      0.40         3\n",
      "           1       0.33      0.20      0.25         5\n",
      "           2       0.00      0.00      0.00         2\n",
      "           3       0.00      0.00      0.00         4\n",
      "           4       0.80      1.00      0.89         4\n",
      "           5       1.00      1.00      1.00         4\n",
      "           6       0.71      1.00      0.83         5\n",
      "           7       0.41      1.00      0.58         7\n",
      "           8       0.00      0.00      0.00         1\n",
      "           9       0.44      0.50      0.47         8\n",
      "          10       1.00      0.25      0.40         4\n",
      "          11       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.56        48\n",
      "   macro avg       0.43      0.44      0.40        48\n",
      "weighted avg       0.51      0.56      0.49        48\n",
      "\n",
      "Evaluating model for vp...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00         1\n",
      "           6       0.00      0.00      0.00         1\n",
      "           7       0.00      0.00      0.00         1\n",
      "           8       0.00      0.00      0.00         1\n",
      "           9       0.00      0.00      0.00         1\n",
      "          10       0.00      0.00      0.00         1\n",
      "          11       0.00      0.00      0.00         1\n",
      "          12       0.00      0.00      0.00         3\n",
      "          13       0.50      1.00      0.67         1\n",
      "          17       0.00      0.00      0.00         0\n",
      "          19       0.00      0.00      0.00         2\n",
      "          20       0.00      0.00      0.00         1\n",
      "          21       0.00      0.00      0.00         1\n",
      "          23       0.00      0.00      0.00         1\n",
      "          24       0.00      0.00      0.00         4\n",
      "          25       1.00      1.00      1.00         4\n",
      "          27       0.00      0.00      0.00         1\n",
      "          29       0.00      0.00      0.00         1\n",
      "          30       0.00      0.00      0.00         2\n",
      "          32       0.00      0.00      0.00         1\n",
      "          33       0.00      0.00      0.00         1\n",
      "          35       0.00      0.00      0.00         3\n",
      "          36       0.00      0.00      0.00         1\n",
      "          38       0.00      0.00      0.00         2\n",
      "          39       0.00      0.00      0.00         0\n",
      "          41       0.00      0.00      0.00         1\n",
      "          42       0.17      0.75      0.27         8\n",
      "\n",
      "    accuracy                           0.23        48\n",
      "   macro avg       0.06      0.09      0.07        48\n",
      "weighted avg       0.12      0.23      0.14        48\n",
      "\n",
      "Evaluating model for name...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.10      1.00      0.18         1\n",
      "           2       0.00      0.00      0.00         1\n",
      "           3       0.00      0.00      0.00         4\n",
      "           4       0.00      0.00      0.00         1\n",
      "           5       1.00      1.00      1.00         1\n",
      "           6       0.50      1.00      0.67         1\n",
      "           7       0.00      0.00      0.00         2\n",
      "           8       1.00      1.00      1.00         3\n",
      "           9       0.00      0.00      0.00         1\n",
      "          10       1.00      1.00      1.00         4\n",
      "          11       0.33      1.00      0.50         2\n",
      "          12       1.00      1.00      1.00         1\n",
      "          13       0.00      0.00      0.00         1\n",
      "          14       0.00      0.00      0.00         3\n",
      "          15       0.33      1.00      0.50         2\n",
      "          18       0.00      0.00      0.00         2\n",
      "          19       1.00      1.00      1.00         1\n",
      "          22       1.00      0.67      0.80         3\n",
      "          24       0.50      1.00      0.67         1\n",
      "          26       0.00      0.00      0.00         2\n",
      "          28       0.00      0.00      0.00         1\n",
      "          30       0.50      1.00      0.67         1\n",
      "          31       0.00      0.00      0.00         1\n",
      "          32       0.33      1.00      0.50         1\n",
      "          33       0.00      0.00      0.00         4\n",
      "          34       1.00      1.00      1.00         1\n",
      "          36       0.00      0.00      0.00         0\n",
      "          37       0.00      0.00      0.00         1\n",
      "          38       0.00      0.00      0.00         1\n",
      "          39       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.46        48\n",
      "   macro avg       0.32      0.46      0.35        48\n",
      "weighted avg       0.36      0.46      0.38        48\n",
      "\n",
      "Evaluating model for gdp_growth...\n",
      "Mean Squared Error for gdp_growth: 0.1978\n",
      "Evaluating model for population_growth...\n",
      "Mean Squared Error for population_growth: 0.0174\n",
      "Evaluating model for gdp_percent_growth...\n",
      "Mean Squared Error for gdp_percent_growth: 0.0011\n",
      "Evaluating model for population_percent_growth...\n",
      "Mean Squared Error for population_percent_growth: 0.0000\n",
      "Accuracy Scores for each categorical target:\n",
      "sign: 0.5625\n",
      "vp: 0.2292\n",
      "name: 0.4583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vallk\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\vallk\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\vallk\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\vallk\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\vallk\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\vallk\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\vallk\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\vallk\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\vallk\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\vallk\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\vallk\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\vallk\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\vallk\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\vallk\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\vallk\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['multi_output_regressor.pkl']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Expand the 'Year' column for the president's terms\n",
    "expanded_rows = []\n",
    "for i, row in pres_terms.iterrows():\n",
    "    for year in range(row['start'], row['stop']):\n",
    "        row_data = row.to_dict()  # Convert row to a dictionary\n",
    "        row_data['year'] = year   # Add the expanded year to the dictionary\n",
    "        expanded_rows.append(row_data)\n",
    "\n",
    "# Create a new DataFrame from the expanded rows\n",
    "expanded_df = pd.DataFrame(expanded_rows)\n",
    "\n",
    "# Step 2: Merge the two DataFrames on the 'Year' column\n",
    "expanded_df = pd.merge(expanded_df, pres_gdp, on=\"year\")\n",
    "\n",
    "# Step 3: Separate categorical and numerical columns\n",
    "categorical_df = expanded_df[cat_c].set_index('year')\n",
    "numerical_df = expanded_df[num_c].set_index('year')\n",
    "\n",
    "# Step 4: Label encode the categorical columns (without one-hot encoding)\n",
    "label_encoders = {}\n",
    "for column in categorical_df.columns:\n",
    "    le = LabelEncoder()\n",
    "    categorical_df[column] = le.fit_transform(categorical_df[column])\n",
    "    label_encoders[column] = le\n",
    "    # Save the label encoders as .pkl files\n",
    "    joblib.dump(le, f\"{column}_encoder.pkl\")  # Save each encoder to a .pkl file\n",
    "\n",
    "\n",
    "# Step 6: Merge categorical and numerical DataFrames\n",
    "processed_df = pd.merge(categorical_df, numerical_df, left_index=True, right_index=True)\n",
    "\n",
    "\n",
    "# Define which columns are categorical and which are continuous\n",
    "categorical_columns = ['sign', 'vp', 'name']\n",
    "continuous_columns = ['gdp_growth', 'population_growth', 'gdp_percent_growth', 'population_percent_growth']\n",
    "\n",
    "# Separate target columns into categorical and continuous\n",
    "y_categorical = processed_df[categorical_columns]\n",
    "y_continuous = processed_df[continuous_columns]\n",
    "\n",
    "# Define feature columns (X)\n",
    "X = processed_df[['bday', 'bmonth', 'party']]\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train_categorical, y_test_categorical = train_test_split(X, y_categorical, test_size=0.2, random_state=42)\n",
    "_, _, y_train_continuous, y_test_continuous = train_test_split(X, y_continuous, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Initialize models for categorical and continuous targets\n",
    "multi_output_classifier = MultiOutputClassifier(LogisticRegression())\n",
    "multi_output_regressor = MultiOutputRegressor(RandomForestRegressor())\n",
    "\n",
    "# Train the models\n",
    "multi_output_classifier.fit(X_train_scaled, y_train_categorical)\n",
    "multi_output_regressor.fit(X_train_scaled, y_train_continuous)\n",
    "\n",
    "# Make predictions on test data\n",
    "y_pred_categorical = multi_output_classifier.predict(X_test_scaled)\n",
    "y_pred_continuous = multi_output_regressor.predict(X_test_scaled)\n",
    "\n",
    "# Initialize a dictionary to store the accuracy scores for each target column\n",
    "accuracy_scores = {}\n",
    "\n",
    "# Loop through each categorical target column and calculate the accuracy\n",
    "for i, target in enumerate(categorical_columns):\n",
    "    print(f\"Evaluating model for {target}...\")\n",
    "    \n",
    "    # Get the true values and predicted values for the current target\n",
    "    y_true = y_test_categorical[target]\n",
    "    y_pred_target = y_pred_categorical[:, i]\n",
    "    \n",
    "    # Calculate accuracy score\n",
    "    accuracy = accuracy_score(y_true, y_pred_target)\n",
    "    accuracy_scores[target] = accuracy\n",
    "    \n",
    "    # Print classification report (for categorical outputs like 'sign', 'VP', and 'Name')\n",
    "    print(classification_report(y_true, y_pred_target))\n",
    "\n",
    "# Loop through each continuous target column and calculate the mean squared error\n",
    "for i, target in enumerate(continuous_columns):\n",
    "    print(f\"Evaluating model for {target}...\")\n",
    "    \n",
    "    # Get the true values and predicted values for the current target\n",
    "    y_true = y_test_continuous[target]\n",
    "    y_pred_target = y_pred_continuous[:, i]\n",
    "    \n",
    "    # Calculate mean squared error\n",
    "    mse = mean_squared_error(y_true, y_pred_target)\n",
    "    print(f\"Mean Squared Error for {target}: {mse:.4f}\")\n",
    "\n",
    "# Print overall accuracy scores for categorical targets\n",
    "print(\"Accuracy Scores for each categorical target:\")\n",
    "for target, score in accuracy_scores.items():\n",
    "    print(f\"{target}: {score:.4f}\")\n",
    "\n",
    "# Save the models\n",
    "joblib.dump(multi_output_classifier, 'multi_output_classifier.pkl')\n",
    "joblib.dump(multi_output_regressor, 'multi_output_regressor.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
