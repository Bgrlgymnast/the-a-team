{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multioutput import MultiOutputRegressor, MultiOutputClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import classification_report, mean_squared_error, accuracy_score  # Include accuracy_score for evaluation\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, GridSearchCV,ShuffleSplit\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sqlalchemy import create_engine, inspect\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pres_gdp = pd.read_csv(\"president_gdp-94.csv\")\n",
    "pres_terms = pd.read_csv(\"president_terms-94.csv\",encoding=\"UTF-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pres_gdp.columns = pres_gdp.columns.str.lower()\n",
    "pres_gdp.columns = pres_gdp.columns.str.replace(\" \",\"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pres_terms.columns = pres_terms.columns.str.lower()\n",
    "pres_terms.columns = pres_terms.columns.str.replace(\" \",\"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PostgreSQL connection parameters\n",
    "# postgres_params = {\n",
    "#     \"database\": \"postgres\", # Insert the name of database\n",
    "#     \"user\": \"postgres\",     # Insert username if different\n",
    "#     \"password\": \"!QAZ1qaz\",        # Insert your password\n",
    "#     \"host\": \"localhost\",    # Replace with your PostgreSQL host if not local\n",
    "#     \"port\": 5432,\n",
    "#     \"options\": \"-c search_path=dbo,public\"}\n",
    "\n",
    "# Establish a connection to PostgreSQL\n",
    "# conn_str = \"postgresql+psycopg2://{user}:{password}@{host}:{port}/{database}\".format(**postgres_params)\n",
    "# postgres_engine = create_engine(conn_str)\n",
    "\n",
    "# Write DataFrame to PostgreSQL\n",
    "# pres_gdp.to_sql('pres_gdp', con=postgres_engine, index=False, if_exists='replace')\n",
    "# pres_terms.to_sql('pres_terms', con=postgres_engine, index=False, if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query=\"\"\"\n",
    "# select * from pres_terms;\n",
    "# \"\"\"\n",
    "# pres_terms = pd.read_sql(sql= query, con= postgres_engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query1=\"\"\"\n",
    "# select * from pres_gdp;\n",
    "# \"\"\"\n",
    "# pres_gdp= pd.read_sql(sql= query1, con= postgres_engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_c = ['Year', 'Name', 'VP', 'BDay', 'Party', 'sign', 'BMonth', 'GDP Growth', 'Population Growth']\n",
    "cat_c = [x.lower() for x in cat_c]\n",
    "cat_c = [x.replace(\" \",\"_\") for x in cat_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_c = ['Year', 'GDP Percent Growth', 'Population Percent Growth']\n",
    "num_c = [x.lower() for x in num_c]\n",
    "num_c = [x.replace(\" \",\"_\") for x in num_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Classifier training completed.\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Regressor training completed.\n",
      "Accuracy for sign: 1.0000\n",
      "Classification report for sign:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         9\n",
      "           1       1.00      1.00      1.00         6\n",
      "           2       1.00      1.00      1.00         3\n",
      "           3       1.00      1.00      1.00        13\n",
      "           4       1.00      1.00      1.00         7\n",
      "           5       1.00      1.00      1.00         6\n",
      "           6       1.00      1.00      1.00         6\n",
      "           7       1.00      1.00      1.00        16\n",
      "           8       1.00      1.00      1.00         7\n",
      "           9       1.00      1.00      1.00        13\n",
      "          10       1.00      1.00      1.00        13\n",
      "          11       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           1.00       101\n",
      "   macro avg       1.00      1.00      1.00       101\n",
      "weighted avg       1.00      1.00      1.00       101\n",
      "\n",
      "Accuracy for vp: 0.7129\n",
      "Classification report for vp:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      1.00      0.50         1\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       1.00      0.50      0.67         2\n",
      "           3       1.00      1.00      1.00         4\n",
      "           4       0.00      0.00      0.00         1\n",
      "           5       1.00      1.00      1.00         1\n",
      "           7       1.00      1.00      1.00         1\n",
      "           8       0.00      0.00      0.00         0\n",
      "           9       1.00      1.00      1.00         2\n",
      "          10       0.33      0.50      0.40         2\n",
      "          11       1.00      1.00      1.00         5\n",
      "          12       0.00      0.00      0.00         1\n",
      "          13       0.00      0.00      0.00         1\n",
      "          14       0.00      0.00      0.00         3\n",
      "          15       1.00      1.00      1.00         3\n",
      "          16       1.00      1.00      1.00         2\n",
      "          17       0.00      0.00      0.00         1\n",
      "          18       0.00      0.00      0.00         0\n",
      "          19       0.00      0.00      0.00         1\n",
      "          20       0.00      0.00      0.00         2\n",
      "          21       0.00      0.00      0.00         1\n",
      "          22       1.00      0.33      0.50         3\n",
      "          23       1.00      1.00      1.00         1\n",
      "          24       1.00      1.00      1.00         2\n",
      "          25       1.00      1.00      1.00         2\n",
      "          26       0.00      0.00      0.00         1\n",
      "          27       0.25      1.00      0.40         1\n",
      "          28       1.00      1.00      1.00         3\n",
      "          29       1.00      1.00      1.00         2\n",
      "          30       1.00      1.00      1.00         1\n",
      "          31       1.00      1.00      1.00         1\n",
      "          33       0.50      1.00      0.67         2\n",
      "          34       1.00      1.00      1.00         1\n",
      "          36       1.00      1.00      1.00         2\n",
      "          37       0.67      0.50      0.57         4\n",
      "          38       1.00      1.00      1.00         7\n",
      "          39       0.00      0.00      0.00         1\n",
      "          40       0.00      0.00      0.00         3\n",
      "          41       0.75      1.00      0.86         3\n",
      "          43       0.00      0.00      0.00         1\n",
      "          44       1.00      0.50      0.67         2\n",
      "          45       1.00      1.00      1.00         2\n",
      "          46       1.00      1.00      1.00         2\n",
      "          47       1.00      1.00      1.00         2\n",
      "          49       0.48      0.81      0.60        16\n",
      "\n",
      "    accuracy                           0.71       101\n",
      "   macro avg       0.58      0.60      0.57       101\n",
      "weighted avg       0.67      0.71      0.67       101\n",
      "\n",
      "Accuracy for name: 0.9406\n",
      "Classification report for name:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         1\n",
      "           1       1.00      1.00      1.00         4\n",
      "           2       1.00      1.00      1.00         1\n",
      "           3       1.00      1.00      1.00         2\n",
      "           4       0.50      1.00      0.67         1\n",
      "           5       1.00      1.00      1.00         1\n",
      "           6       1.00      1.00      1.00         1\n",
      "           7       0.00      0.00      0.00         1\n",
      "           8       1.00      1.00      1.00         1\n",
      "          10       1.00      1.00      1.00         4\n",
      "          11       1.00      1.00      1.00         2\n",
      "          12       0.33      0.50      0.40         2\n",
      "          13       0.67      0.50      0.57         4\n",
      "          14       0.67      1.00      0.80         2\n",
      "          15       1.00      1.00      1.00         5\n",
      "          16       1.00      1.00      1.00         2\n",
      "          18       1.00      1.00      1.00         2\n",
      "          19       1.00      1.00      1.00         2\n",
      "          20       1.00      1.00      1.00         5\n",
      "          21       1.00      1.00      1.00         5\n",
      "          22       1.00      1.00      1.00         2\n",
      "          23       1.00      1.00      1.00         2\n",
      "          24       1.00      0.50      0.67         2\n",
      "          26       1.00      1.00      1.00         3\n",
      "          27       0.00      0.00      0.00         0\n",
      "          28       1.00      1.00      1.00         1\n",
      "          29       1.00      1.00      1.00         5\n",
      "          30       1.00      1.00      1.00         7\n",
      "          31       1.00      1.00      1.00         1\n",
      "          32       1.00      1.00      1.00         4\n",
      "          33       1.00      1.00      1.00         3\n",
      "          34       1.00      1.00      1.00         2\n",
      "          35       1.00      1.00      1.00         1\n",
      "          36       1.00      1.00      1.00         3\n",
      "          37       1.00      1.00      1.00         4\n",
      "          38       1.00      1.00      1.00         1\n",
      "          39       1.00      0.75      0.86         4\n",
      "          40       1.00      1.00      1.00         3\n",
      "          41       1.00      1.00      1.00         1\n",
      "          42       1.00      1.00      1.00         2\n",
      "          43       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.94       101\n",
      "   macro avg       0.91      0.91      0.90       101\n",
      "weighted avg       0.95      0.94      0.94       101\n",
      "\n",
      "Mean Squared Error for gdp_growth: 0.1987\n",
      "Mean Squared Error for population_growth: 0.0632\n",
      "Mean Squared Error for gdp_percent_growth: 0.0116\n",
      "Mean Squared Error for population_percent_growth: 0.0101\n",
      "\n",
      "Overall Accuracy Scores for Categorical Targets:\n",
      "sign: 1.0000\n",
      "vp: 0.7129\n",
      "name: 0.9406\n",
      "\n",
      "Overall Mean Squared Errors for Continuous Targets:\n",
      "gdp_growth: 0.1987\n",
      "population_growth: 0.0632\n",
      "gdp_percent_growth: 0.0116\n",
      "population_percent_growth: 0.0101\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Assume pres_terms, pres_gdp, cat_c, num_c are already defined\n",
    "\n",
    "# Step 1: Expand the 'Year' column for the president's terms\n",
    "expanded_rows = []\n",
    "for i, row in pres_terms.iterrows():\n",
    "    for year in range(row['start'], row['stop'] + 1):\n",
    "        row_data = row.to_dict()\n",
    "        row_data['year'] = year\n",
    "        expanded_rows.append(row_data)\n",
    "\n",
    "# Create a new DataFrame from the expanded rows\n",
    "expanded_df = pd.DataFrame(expanded_rows)\n",
    "\n",
    "# Step 2: Merge the two DataFrames on the 'Year' column\n",
    "expanded_df = pd.merge(expanded_df, pres_gdp, on=\"year\", how=\"left\")\n",
    "\n",
    "# Step 3: Separate categorical and numerical columns\n",
    "categorical_df = expanded_df[cat_c].set_index('year')\n",
    "numerical_df = expanded_df[num_c].set_index('year')\n",
    "\n",
    "# Step 4: Label encode the categorical columns (without one-hot encoding)\n",
    "label_encoders = {}\n",
    "for column in categorical_df.columns:\n",
    "    le = LabelEncoder()\n",
    "    categorical_df[column] = le.fit_transform(categorical_df[column])\n",
    "    label_encoders[column] = le\n",
    "    joblib.dump(le, f\"{column}_encoder.pkl\")\n",
    "\n",
    "# Step 5: Merge categorical and numerical DataFrames\n",
    "processed_df = pd.merge(categorical_df, numerical_df, left_index=True, right_index=True)\n",
    "\n",
    "# Define which columns are categorical and which are continuous\n",
    "categorical_columns = ['sign', 'vp', 'name']\n",
    "continuous_columns = ['gdp_growth', 'population_growth', 'gdp_percent_growth', 'population_percent_growth']\n",
    "\n",
    "# Separate target columns into categorical and continuous\n",
    "y_categorical = processed_df[categorical_columns]\n",
    "y_continuous = processed_df[continuous_columns]\n",
    "\n",
    "# Define feature columns (X)\n",
    "X = processed_df[['bday', 'bmonth', 'party']]\n",
    "\n",
    "# Step 6: Perform non-stratified splitting using ShuffleSplit\n",
    "split = ShuffleSplit(n_splits=5, test_size=0.2, random_state=42)\n",
    "for train_idx, test_idx in split.split(X):\n",
    "    X_train_strat, X_test_strat = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train_categorical_strat, y_test_categorical_strat = y_categorical.iloc[train_idx], y_categorical.iloc[test_idx]\n",
    "    y_train_continuous_strat, y_test_continuous_strat = y_continuous.iloc[train_idx], y_continuous.iloc[test_idx]\n",
    "\n",
    "# Step 7: Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_strat)\n",
    "X_test_scaled = scaler.transform(X_test_strat)\n",
    "\n",
    "# Step 8: Define hyperparameters for RandomForestClassifier and RandomForestRegressor\n",
    "param_grid_classifier = {\n",
    "    'estimator__n_estimators': [50, 100, 200],\n",
    "    'estimator__max_depth': [10, 20, 30],\n",
    "    'estimator__min_samples_split': [2, 5, 10],\n",
    "    'estimator__min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "param_grid_regressor = {\n",
    "    'estimator__n_estimators': [50, 100, 200],\n",
    "    'estimator__max_depth': [10, 20, 30],\n",
    "    'estimator__min_samples_split': [2, 5, 10],\n",
    "    'estimator__min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Step 9: Initialize RandomForest models for categorical and continuous targets\n",
    "multi_output_classifier = MultiOutputClassifier(RandomForestClassifier(random_state=42))\n",
    "multi_output_regressor = MultiOutputRegressor(RandomForestRegressor(random_state=42))\n",
    "\n",
    "# Step 10: Use ShuffleSplit for cross-validation\n",
    "split_cv = ShuffleSplit(n_splits=5, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 11: Define training functions that return the trained models\n",
    "def train_classifier():\n",
    "    # Hyperparameter search for RandomForestClassifier\n",
    "    grid_search_classifier = RandomizedSearchCV(\n",
    "        multi_output_classifier,\n",
    "        param_distributions=param_grid_classifier,\n",
    "        n_iter=10,\n",
    "        cv=split_cv,  # ShuffleSplit for cross-validation\n",
    "        verbose=2,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    grid_search_classifier.fit(X_train_scaled, y_train_categorical_strat)\n",
    "    print(\"Classifier training completed.\")\n",
    "    # Save the classifier model\n",
    "    joblib.dump(grid_search_classifier.best_estimator_, 'multi_output_classifier.pkl')\n",
    "    return grid_search_classifier\n",
    "\n",
    "def train_regressor():\n",
    "    # Hyperparameter search for RandomForestRegressor\n",
    "    grid_search_regressor = RandomizedSearchCV(\n",
    "        multi_output_regressor,\n",
    "        param_distributions=param_grid_regressor,\n",
    "        n_iter=10,\n",
    "        cv=split_cv,  # ShuffleSplit for cross-validation\n",
    "        verbose=2,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    grid_search_regressor.fit(X_train_scaled, y_train_continuous_strat)\n",
    "    print(\"Regressor training completed.\")\n",
    "    # Save the regressor model\n",
    "    joblib.dump(grid_search_regressor.best_estimator_, 'multi_output_regressor.pkl')\n",
    "    return grid_search_regressor\n",
    "\n",
    "# Call the training functions and store the trained models\n",
    "grid_search_classifier = train_classifier()\n",
    "grid_search_regressor = train_regressor()\n",
    "\n",
    "# Step 15: Evaluate the models\n",
    "y_pred_categorical = grid_search_classifier.predict(X_test_scaled)\n",
    "y_pred_continuous = grid_search_regressor.predict(X_test_scaled)\n",
    "\n",
    "# Step 16: Accuracy and Error Calculation\n",
    "accuracy_scores = {}\n",
    "mse_scores = {}\n",
    "\n",
    "# Evaluate categorical targets (classification)\n",
    "for i, target in enumerate(categorical_columns):\n",
    "    y_true = y_test_categorical_strat[target]\n",
    "    y_pred_target = y_pred_categorical[:, i]\n",
    "    accuracy = accuracy_score(y_true, y_pred_target)\n",
    "    accuracy_scores[target] = accuracy\n",
    "    print(f\"Accuracy for {target}: {accuracy:.4f}\")\n",
    "    print(f\"Classification report for {target}:\\n\", classification_report(y_true, y_pred_target, zero_division=0))\n",
    "\n",
    "# Evaluate continuous targets (regression)\n",
    "for i, target in enumerate(continuous_columns):\n",
    "    y_true = y_test_continuous_strat[target]\n",
    "    y_pred_target = y_pred_continuous[:, i]\n",
    "    mse = mean_squared_error(y_true, y_pred_target)\n",
    "    mse_scores[target] = mse\n",
    "    print(f\"Mean Squared Error for {target}: {mse:.4f}\")\n",
    "\n",
    "# Optional: You can print overall results for better summary\n",
    "print(\"\\nOverall Accuracy Scores for Categorical Targets:\")\n",
    "for target, accuracy in accuracy_scores.items():\n",
    "    print(f\"{target}: {accuracy:.4f}\")\n",
    "\n",
    "print(\"\\nOverall Mean Squared Errors for Continuous Targets:\")\n",
    "for target, mse in mse_scores.items():\n",
    "    print(f\"{target}: {mse:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dev)",
   "language": "python",
   "name": "dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
